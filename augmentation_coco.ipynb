{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "augmentation_coco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chauminhnguyen/augumentation_coco/blob/main/augmentation_coco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grqJLrvePrGP"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60rYDkO0NcX8",
        "outputId": "3fdec444-6053-470e-945f-e0288bfe4599"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXD_TNeblW4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ce8e57-6518-4dc9-ed42-ff7b972f9427"
      },
      "source": [
        "!pip install --upgrade albumentations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/b2/9492c74a5d260bc39f0cba9fcdc6652d0f87d342aaeb32197c62029f82df/albumentations-0.5.1-py3-none-any.whl (71kB)\n",
            "\r\u001b[K     |████▋                           | 10kB 14.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 20kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.16.2)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/e9/57d869561389884136be65a2d1bc038fe50171e2ba348fda269a4aab8032/opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7MB)\n",
            "\u001b[K     |████████████████████████████████| 36.7MB 132kB/s \n",
            "\u001b[?25hCollecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n",
            "Installing collected packages: opencv-python-headless, imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.5.1 imgaug-0.4.0 opencv-python-headless-4.4.0.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj0p38fP9aSc"
      },
      "source": [
        "import imageio\n",
        "import albumentations as A\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from math import trunc\n",
        "from PIL import Image as PILImage\n",
        "import cv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_TgUE52oWBX"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHPmcjTCqeox"
      },
      "source": [
        "# Load the dataset json\n",
        "class CocoDataset():\n",
        "    '''\n",
        "    annotation_path: json\n",
        "    image_dir: folder of images\n",
        "\n",
        "    '''\n",
        "    def __init__(self, annotation_path, image_dir):\n",
        "        self.annotation_path = annotation_path\n",
        "        self.image_dir = image_dir\n",
        "        \n",
        "        json_file = open(self.annotation_path)\n",
        "        self.coco = json.load(json_file)\n",
        "        json_file.close()\n",
        "        \n",
        "        # self.process_info()\n",
        "        # self.process_licenses()\n",
        "        self.process_categories()\n",
        "        self.process_images()\n",
        "        self.process_segmentations()\n",
        "\n",
        "    \n",
        "    def display_image(self, image_id, show_polys=True, show_labels=True, show_bbox=True, show_crowds=True, use_url=False):\n",
        "        # Print the image info\n",
        "        image = self.images[image_id]\n",
        "        image_path = os.path.join(self.image_dir, image['file_name'])\n",
        "        image = PILImage.open(image_path)\n",
        "        \n",
        "        # Calculate the size and adjusted display size\n",
        "        max_width = 900\n",
        "        image_width, image_height = image.size\n",
        "        adjusted_width = min(image_width, max_width)\n",
        "        adjusted_ratio = adjusted_width / image_width\n",
        "        adjusted_height = adjusted_ratio * image_height\n",
        "        \n",
        "        # Create list of polygons to be drawn\n",
        "        polygons = {}\n",
        "        bbox_polygons = {}\n",
        "        rle_regions = {}\n",
        "        poly_colors = {}\n",
        "        polys = []\n",
        "        for i, segm in enumerate(self.segmentations[image_id]):\n",
        "            polygons_list = []\n",
        "            if segm['iscrowd'] != 0:\n",
        "                # Gotta decode the RLE\n",
        "                px = 0\n",
        "                x, y = 0, 0\n",
        "                rle_list = []\n",
        "                for j, counts in enumerate(segm['segmentation']['counts']):\n",
        "                    if j % 2 == 0:\n",
        "                        # Empty pixels\n",
        "                        px += counts\n",
        "                    else:\n",
        "                        # Need to draw on these pixels, since we are drawing in vector form,\n",
        "                        # we need to draw horizontal lines on the image\n",
        "                        x_start = trunc(trunc(px / image_height) * adjusted_ratio)\n",
        "                        y_start = trunc(px % image_height * adjusted_ratio)\n",
        "                        px += counts\n",
        "                        x_end = trunc(trunc(px / image_height) * adjusted_ratio)\n",
        "                        y_end = trunc(px % image_height * adjusted_ratio)\n",
        "                        if x_end == x_start:\n",
        "                            # This is only on one line\n",
        "                            rle_list.append({'x': x_start, 'y': y_start, 'width': 1 , 'height': (y_end - y_start)})\n",
        "                        if x_end > x_start:\n",
        "                            # This spans more than one line\n",
        "                            # Insert top line first\n",
        "                            rle_list.append({'x': x_start, 'y': y_start, 'width': 1, 'height': (image_height - y_start)})\n",
        "                            \n",
        "                            # Insert middle lines if needed\n",
        "                            lines_spanned = x_end - x_start + 1 # total number of lines spanned\n",
        "                            full_lines_to_insert = lines_spanned - 2\n",
        "                            if full_lines_to_insert > 0:\n",
        "                                full_lines_to_insert = trunc(full_lines_to_insert * adjusted_ratio)\n",
        "                                rle_list.append({'x': (x_start + 1), 'y': 0, 'width': full_lines_to_insert, 'height': image_height})\n",
        "                                \n",
        "                            # Insert bottom line\n",
        "                            rle_list.append({'x': x_end, 'y': 0, 'width': 1, 'height': y_end})\n",
        "                if len(rle_list) > 0:\n",
        "                    rle_regions[segm['id']] = rle_list  \n",
        "            else:\n",
        "                # Add the polygon segmentation\n",
        "                for segmentation_points in segm['segmentation']:\n",
        "                    segmentation_points = np.multiply(segmentation_points, adjusted_ratio).astype(int)\n",
        "                    polygons_list.append(str(segmentation_points).lstrip('[').rstrip(']'))\n",
        "\n",
        "            polygons[segm['id']] = polygons_list\n",
        "            \n",
        "            bbox = segm['bbox']\n",
        "            bbox_points = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1],\n",
        "                           bbox[0] + bbox[2], bbox[1] + bbox[3], bbox[0], bbox[1] + bbox[3],\n",
        "                           bbox[0], bbox[1]]\n",
        "            bbox_points = np.multiply(bbox_points, adjusted_ratio).astype(int)\n",
        "            polys.append(bbox_points[:-2])\n",
        "        return image_path, image_width, image_height, self.segmentations[image_id]\n",
        "       \n",
        "    # def process_info(self):\n",
        "    #     self.info = self.coco.get('info')\n",
        "    \n",
        "    # def process_licenses(self):\n",
        "    #     self.licenses = self.coco.get('licenses')\n",
        "    \n",
        "    def get_max_image_id(self):\n",
        "        return list(self.images.keys())[-1]\n",
        "\n",
        "    def process_categories(self):\n",
        "        self.categories = {}\n",
        "        self.super_categories = {}\n",
        "        for category in self.coco['categories']:\n",
        "            cat_id = category['id']\n",
        "            super_category = category['supercategory']\n",
        "            \n",
        "            # Add category to the categories dict\n",
        "            if cat_id not in self.categories:\n",
        "                self.categories[cat_id] = category\n",
        "            else:\n",
        "                print(\"ERROR: Skipping duplicate category id: {}\".format(category))\n",
        "\n",
        "            # Add category to super_categories dict\n",
        "            if super_category not in self.super_categories:\n",
        "                self.super_categories[super_category] = {cat_id} # Create a new set with the category id\n",
        "            else:\n",
        "                self.super_categories[super_category] |= {cat_id} # Add category id to the set\n",
        "                \n",
        "    def process_images(self):\n",
        "        self.images = {}\n",
        "        for image in self.coco['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in self.images:\n",
        "                print(\"ERROR: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                self.images[image_id] = image\n",
        "\n",
        "    def process_segmentations(self):\n",
        "        self.segmentations = {}\n",
        "        for segmentation in self.coco['annotations']:\n",
        "            image_id = segmentation['image_id']\n",
        "            if image_id not in self.segmentations:\n",
        "                self.segmentations[image_id] = []\n",
        "            self.segmentations[image_id].append(segmentation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_G3XqI-8efV"
      },
      "source": [
        "## Export to JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNFFEIRi8eu2"
      },
      "source": [
        "def img_convert2json(width, height, image_id, images):\n",
        "    '''\n",
        "    images: array type\n",
        "    '''\n",
        "    images.append(\n",
        "        {\n",
        "            \"file_name\": str(image_id) + \".png\",\n",
        "            \"height\": height,\n",
        "            \"width\": width,\n",
        "            \"id\": image_id,\n",
        "            \"street_id\": 0\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def ann_convert2json(area, image_id, bbox, category_id, id, annotations):\n",
        "    '''\n",
        "    annotations: array type\n",
        "    '''\n",
        "    annotations.append(\n",
        "        {\n",
        "            \"segmentation\": [],\n",
        "            \"area\": int(area),\n",
        "            \"iscrowd\": 0,\n",
        "            \"image_id\": int(image_id),\n",
        "            \"bbox\": [\n",
        "                    int(bbox[0]),\n",
        "                    int(bbox[1]),\n",
        "                    int(bbox[2]),\n",
        "                    int(bbox[3]),\n",
        "                    ],\n",
        "            \"category_id\": int(category_id),\n",
        "            \"id\": int(id)\n",
        "        }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bur9korb7SZO"
      },
      "source": [
        "def export2json(annotations, images, annotation_path):\n",
        "    # save to json:\n",
        "    s = json.load(open(annotation_path, 'r'))\n",
        "    s['images'].extend(images)\n",
        "    s['annotations'].extend(annotations)\n",
        "    s = json.dumps(s)\n",
        "    out_file = '/content/final_augmentation_dataset.json'\n",
        "    out = open(out_file, 'w')\n",
        "    out.write(s)\n",
        "    out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnwCBIL7IyJx"
      },
      "source": [
        "## Augment Bounding Boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts5c7xjd2PT8"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpRJ6Im9qr_h"
      },
      "source": [
        "def save_image(img, img_name):\n",
        "    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(img_name, im_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hP-E2DY2Se1"
      },
      "source": [
        "### Run Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2nWK4qF7_Pg"
      },
      "source": [
        "annotation_path = '/content/drive/MyDrive/Zalo AI/za_traffic_2020/traffic_train/train_traffic_sign_dataset_merging_NMS_rmBbox.json'\n",
        "image_dir = '/content/drive/MyDrive/Zalo AI/za_traffic_2020/traffic_train/images'\n",
        "augmentation_img_path = \"/content/img1/\"\n",
        "\n",
        "coco_dataset = CocoDataset(annotation_path, image_dir)\n",
        "max_index = coco_dataset.get_max_image_id()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtrPkZKW9wWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4390dea0-bdcf-42b3-b9dd-619e90d6c563"
      },
      "source": [
        "# Albumentations path with bounding boxes\n",
        "\n",
        "RGB = A.Compose([A.RGBShift(r_shift_limit=30, g_shift_limit=30, b_shift_limit=30, p=1)],bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
        "\n",
        "brightness =  A.Compose([A.RandomBrightnessContrast(brightness_limit=0.2,contrast_limit=0.4,p=1)],bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
        "\n",
        "rotate = A.Compose([A.Rotate(limit=15,p=0.3)],bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
        "\n",
        "posterize = A.Compose([A.Posterize(p=1)],bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
        "\n",
        "perspective = A.Compose([A.IAAPerspective(scale=(0.01, 0.15),p=1)],bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']))\n",
        "\n",
        "it_ann = 0\n",
        "it_img = 0\n",
        "annotations = []\n",
        "images = []\n",
        "\n",
        "image_indexes = os.listdir(image_dir)\n",
        "\n",
        "for image_index in image_indexes:\n",
        "\n",
        "    image_index = int(image_index.split('.')[0])\n",
        "    try:\n",
        "        image_path, image_width, image_height, segm = coco_dataset.display_image(image_index, use_url=False)\n",
        "\n",
        "        bboxes = [segm[i]['bbox'] for i in range(len(segm))]\n",
        "        labels = [segm[i]['category_id'] for i in range(len(segm))]\n",
        "        image = imageio.imread(image_path)\n",
        "        \n",
        "        transformer = []\n",
        "        transformer.append(RGB(image=image, bboxes=bboxes, category_ids=labels))\n",
        "        transformer.append(brightness(image=image, bboxes=bboxes, category_ids=labels))\n",
        "        transformer.append(rotate(image=image, bboxes=bboxes, category_ids=labels))\n",
        "        transformer.append(posterize(image=image, bboxes=bboxes, category_ids=labels))\n",
        "        transformer.append(perspective(image=image, bboxes=bboxes, category_ids=labels))\n",
        "\n",
        "        # Crop image to 4 path\n",
        "        crop_image = []\n",
        "\n",
        "        trans_topleft = A.Compose([\n",
        "                A.Crop(x_min=0, y_min=0,x_max=int(image.shape[1]/2)+40,y_max=int(image.shape[0]/2)+40)],\n",
        "                bbox_params=A.BboxParams(format='coco',min_visibility=0.2, label_fields=['category_ids']),)\n",
        "\n",
        "        trans_topright = A.Compose([\n",
        "                A.Crop(x_min=int(image.shape[1]/2)-40, y_min=0,x_max=image.shape[1],y_max=int(image.shape[0]/2)+40)],\n",
        "                bbox_params=A.BboxParams(format='coco',min_visibility=0.2, label_fields=['category_ids']),)\n",
        "\n",
        "        trans_botleft = A.Compose([\n",
        "                A.Crop(x_min=0, y_min=int(image.shape[0]/2)-40,x_max=int(image.shape[1]/2)+40,y_max=image.shape[0])],\n",
        "                bbox_params=A.BboxParams(format='coco',min_visibility=0.2, label_fields=['category_ids']),)\n",
        "\n",
        "        trans_botright = A.Compose([\n",
        "                A.Crop(x_min=int(image.shape[1]/2)-40, y_min=int(image.shape[0]/2)-40,x_max=image.shape[1],y_max=image.shape[0])],\n",
        "                bbox_params=A.BboxParams(format='coco',min_visibility=0.2, label_fields=['category_ids']),)\n",
        "\n",
        "        for transformed in transformer:\n",
        "          crop_image.append(trans_topleft(image=transformed['image'], bboxes=transformed['bboxes'], category_ids=transformed['category_ids']))\n",
        "          crop_image.append(trans_topright(image=transformed['image'], bboxes=transformed['bboxes'], category_ids=transformed['category_ids']))\n",
        "          crop_image.append(trans_botleft(image=transformed['image'], bboxes=transformed['bboxes'], category_ids=transformed['category_ids']))\n",
        "          crop_image.append(trans_botright(image=transformed['image'], bboxes=transformed['bboxes'], category_ids=transformed['category_ids']))\n",
        "\n",
        "        # Remove NULL BBX\n",
        "        crop_image_out = []\n",
        "\n",
        "        fullsize =  A.Compose([\n",
        "                A.Resize(height=image.shape[0], width = image.shape[1])],\n",
        "                bbox_params=A.BboxParams(format='coco',min_visibility=0.2, label_fields=['category_ids']),)\n",
        "\n",
        "        for transformed in crop_image:\n",
        "          if transformed['bboxes'] != []:\n",
        "            transformed = fullsize(image=transformed['image'],bboxes=transformed['bboxes'],category_ids=transformed['category_ids'])\n",
        "            crop_image_out.append(transformed)\n",
        "        for transformed in crop_image_out:\n",
        "            it_img += 1\n",
        "            has_bb = False\n",
        "            for i in range(len(transformed['bboxes'])):\n",
        "                area = transformed['bboxes'][i][2] * transformed['bboxes'][i][3]\n",
        "                if area > 25:\n",
        "                    has_bb = True\n",
        "                    ann_convert2json(area, max_index + it_img, list(transformed['bboxes'][i]), transformed['category_ids'][i], it_ann, annotations)\n",
        "                    it_ann += 1\n",
        "            if has_bb:\n",
        "                img_convert2json(image_width, image_height, max_index + it_img, images)\n",
        "                save_image(transformed['image'], augmentation_img_path + str(max_index + it_img) + \".png\")\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "export2json(annotations, images, annotation_path)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}